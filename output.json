{
  "tree": {
    "name": ".",
    "directories": [
      {
        "name": "RAG",
        "directories": [],
        "files": [
          {
            "name": "__init__.py",
            "content_index": 0
          },
          {
            "name": "document_loader.py",
            "content_index": 1
          },
          {
            "name": "embeddings.py",
            "content_index": 2
          },
          {
            "name": "retriever.py",
            "content_index": 3
          },
          {
            "name": "text_splitter.py",
            "content_index": 4
          },
          {
            "name": "vector_store.py",
            "content_index": 5
          }
        ]
      },
      {
        "name": "backend",
        "directories": [],
        "files": [
          {
            "name": "ai_service.py",
            "content_index": 6
          },
          {
            "name": "main.py",
            "content_index": 7
          },
          {
            "name": "rag.py",
            "content_index": 8
          },
          {
            "name": "requirements.txt",
            "content_index": 9
          }
        ]
      },
      {
        "name": "data",
        "directories": [
          {
            "name": "data\\documents",
            "directories": [],
            "files": []
          },
          {
            "name": "data\\vector_store",
            "directories": [],
            "files": []
          }
        ],
        "files": []
      },
      {
        "name": "frontend",
        "directories": [],
        "files": [
          {
            "name": "index.html",
            "content_index": 11
          },
          {
            "name": "script.js",
            "content_index": 12
          },
          {
            "name": "style.css",
            "content_index": 13
          }
        ]
      }
    ],
    "files": [
      {
        "name": "config.py",
        "content_index": 10
      },
      {
        "name": "run_demo.py",
        "content_index": 14
      }
    ]
  },
  "code_blocks": [
    {
      "filename": "RAG\\__init__.py",
      "content": "from .document_loader import DocumentLoader\nfrom .text_splitter import TextSplitter\nfrom .embeddings import EmbeddingModel\nfrom .vector_store import VectorStore\nfrom .retriever import Retriever\nfrom config import DOCUMENTS_DIR, VECTOR_STORE_DIR\nimport os\n\ndef initialize_rag_system(force_rebuild=False):\n    \"\"\"初始化RAG系统\"\"\"\n    # 检查向量存储是否存在\n    vector_store = VectorStore()\n    if not force_rebuild and vector_store.index_path.exists():\n        print(\"Using existing vector store\")\n        return Retriever()\n    \n    print(\"Building new vector store...\")\n    \n    # 加载文档\n    loader = DocumentLoader()\n    documents = loader.load_documents()\n    if not documents:\n        print(\"No documents found to build vector store\")\n        return Retriever()\n    \n    # 分割文档\n    splitter = TextSplitter()\n    chunks = splitter.split_documents(documents)\n    print(f\"Split {len(documents)} documents into {len(chunks)} chunks\")\n    \n    # 生成嵌入\n    embedding_model = EmbeddingModel()\n    texts = [chunk[\"text\"] for chunk in chunks]\n    embeddings = embedding_model.embed_texts(texts)\n    \n    # 添加到向量存储\n    vector_store.add_chunks(chunks, embeddings)\n    \n    print(\"Vector store built successfully\")\n    return Retriever()"
    },
    {
      "filename": "RAG\\document_loader.py",
      "content": "import os\nfrom pathlib import Path\nfrom config import DOCUMENTS_DIR, RAG_CONFIG\nimport PyPDF2\nfrom docx import Document\nimport markdown\n\nclass DocumentLoader:\n    def __init__(self):\n        self.extensions = RAG_CONFIG[\"document_loader\"][\"extensions\"]\n        self.documents_dir = Path(DOCUMENTS_DIR)\n        self.documents_dir.mkdir(parents=True, exist_ok=True)\n    \n    def load_documents(self):\n        \"\"\"加载文档目录中的所有支持文档\"\"\"\n        documents = []\n        \n        for ext in self.extensions:\n            for file_path in self.documents_dir.glob(f\"*{ext}\"):\n                content = self._load_file(file_path)\n                if content:\n                    documents.append({\n                        \"file_path\": str(file_path),\n                        \"content\": content\n                    })\n        \n        return documents\n    \n    def _load_file(self, file_path):\n        \"\"\"根据文件类型加载内容\"\"\"\n        ext = file_path.suffix.lower()\n        \n        try:\n            if ext == \".txt\":\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    return f.read()\n            \n            elif ext == \".pdf\":\n                content = []\n                with open(file_path, 'rb') as f:\n                    pdf_reader = PyPDF2.PdfReader(f)\n                    for page in pdf_reader.pages:\n                        content.append(page.extract_text())\n                return \"\\n\".join(content)\n            \n            elif ext == \".docx\":\n                doc = Document(file_path)\n                return \"\\n\".join([para.text for para in doc.paragraphs])\n            \n            elif ext == \".md\":\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    return markdown.markdown(f.read())\n            \n            else:\n                print(f\"Unsupported file type: {ext}\")\n                return None\n        except Exception as e:\n            print(f\"Error loading {file_path}: {str(e)}\")\n            return None\n\n    def add_document(self, file_path):\n        \"\"\"添加单个文档到存储\"\"\"\n        dest_path = self.documents_dir / Path(file_path).name\n        # 实际项目中应处理文件覆盖等问题\n        with open(file_path, 'rb') as src, open(dest_path, 'wb') as dst:\n            dst.write(src.read())\n        return str(dest_path)"
    },
    {
      "filename": "RAG\\embeddings.py",
      "content": "import requests\nimport numpy as np\nfrom typing import List\nfrom config import RAG_CONFIG\n\nclass EmbeddingModel:\n    def __init__(self):\n        config = RAG_CONFIG[\"embeddings\"]\n        self.model_type = config[\"model_type\"]\n        self.model_name = config[\"model_name\"]\n    \n    def embed_texts(self, texts: List[str]) -> List[List[float]]:\n        \"\"\"将文本列表转换为嵌入向量\"\"\"\n        if self.model_type == \"ollama\":\n            return self._embed_with_ollama(texts)\n        elif self.model_type == \"huggingface\":\n            return self._embed_with_huggingface(texts)\n        else:\n            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n    \n    def _embed_with_ollama(self, texts: List[str]) -> List[List[float]]:\n        \"\"\"使用Ollama API生成嵌入\"\"\"\n        embeddings = []\n        for text in texts:\n            try:\n                response = requests.post(\n                    \"http://localhost:11434/api/embeddings\",\n                    json={\n                        \"model\": self.model_name,\n                        \"prompt\": text\n                    }\n                )\n                if response.status_code == 200:\n                    embeddings.append(response.json().get(\"embedding\", []))\n                else:\n                    print(f\"Error embedding text: {response.text}\")\n                    embeddings.append([])\n            except Exception as e:\n                print(f\"Ollama embedding error: {str(e)}\")\n                embeddings.append([])\n        \n        return embeddings\n    \n    def _embed_with_huggingface(self, texts: List[str]) -> List[List[float]]:\n        \"\"\"使用Hugging Face模型生成嵌入（占位符）\"\"\"\n        # 实际项目中应实现Hugging Face嵌入\n        print(\"Hugging Face embeddings not implemented yet\")\n        return [np.random.rand(768).tolist() for _ in texts]"
    },
    {
      "filename": "RAG\\retriever.py",
      "content": "from .embeddings import EmbeddingModel\nfrom .vector_store import VectorStore\nfrom config import RAG_CONFIG\nfrom pathlib import Path\nclass Retriever:\n    def __init__(self):\n        self.embedding_model = EmbeddingModel()\n        self.vector_store = VectorStore()\n        self.vector_store.load_index()\n        self.top_k = RAG_CONFIG[\"retriever\"][\"top_k\"]\n        self.score_threshold = RAG_CONFIG[\"retriever\"][\"score_threshold\"]\n    \n    def retrieve(self, query: str) -> str:\n        \"\"\"检索与查询相关的上下文\"\"\"\n        # 生成查询嵌入\n        query_embedding = self.embedding_model.embed_texts([query])\n        if not query_embedding or not query_embedding[0]:\n            return \"\"\n        \n        # 执行相似度搜索\n        results = self.vector_store.similarity_search(\n            query_embedding[0], \n            top_k=self.top_k\n        )\n        \n        # 构建上下文\n        context = []\n        for score, chunk_id, chunk_data in results:\n            if score >= self.score_threshold:\n                context.append({\n                    \"text\": chunk_data[\"text\"],\n                    \"source\": chunk_data[\"source\"],\n                    \"score\": round(score, 3)\n                })\n        \n        # 格式化上下文\n        return self._format_context(context)\n    \n    def _format_context(self, context_items) -> str:\n        \"\"\"格式化检索到的上下文\"\"\"\n        if not context_items:\n            return \"\"\n        \n        context_str = \"检索到的相关上下文信息：\\n\\n\"\n        for i, item in enumerate(context_items, 1):\n            source_name = Path(item[\"source\"]).name\n            context_str += f\"### 上下文片段 {i} (来源: {source_name}, 相似度: {item['score']})\\n\"\n            context_str += f\"{item['text']}\\n\\n\"\n        \n        return context_str.strip()"
    },
    {
      "filename": "RAG\\text_splitter.py",
      "content": "import re\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom config import RAG_CONFIG\nfrom pathlib import Path\n\nclass TextSplitter:\n    def __init__(self):\n        config = RAG_CONFIG[\"text_splitter\"]\n        self.splitter = RecursiveCharacterTextSplitter(\n            chunk_size=config[\"chunk_size\"],\n            chunk_overlap=config[\"chunk_overlap\"],\n            separators=[\"\\n\\n\", \"\\n\", \"。\", \"？\", \"！\", \"；\", \" \", \"\"],\n            keep_separator=True\n        )\n    \n    def split_documents(self, documents):\n        \"\"\"分割文档为文本块\"\"\"\n        chunks = []\n        for doc in documents:\n            content = doc[\"content\"]\n            # 清理多余空白\n            content = re.sub(r'\\s+', ' ', content).strip()\n            # 分割文本\n            split_texts = self.splitter.split_text(content)\n            \n            for i, text in enumerate(split_texts):\n                chunks.append({\n                    \"text\": text,\n                    \"source\": doc[\"file_path\"],\n                    \"chunk_id\": f\"{Path(doc['file_path']).stem}_{i}\"\n                })\n        \n        return chunks"
    },
    {
      "filename": "RAG\\vector_store.py",
      "content": "# RAG/vector_store.py\nfrom annoy import AnnoyIndex\n\nimport json\nimport numpy as np\nimport os\nfrom config import VECTOR_STORE_DIR, RAG_CONFIG\nfrom pathlib import Path\n\nclass VectorStore:\n    def __init__(self):\n        self.store_dir = Path(VECTOR_STORE_DIR)\n        self.store_dir.mkdir(parents=True, exist_ok=True)\n        config = RAG_CONFIG[\"vector_store\"]\n        self.store_type = config[\"type\"]  # 保留配置字段（可选）\n        self.index_name = config[\"index_name\"]\n        self.index_path = self.store_dir / f\"{self.index_name}.ann\"  # 改为 .ann 后缀\n        self.metadata_path = self.store_dir / f\"{self.index_name}_metadata.json\"\n        self.index = None\n        self.metadata = {}\n        self.dim = 768  # 假设嵌入维度为 768（根据实际模型调整）\n        self.distance_metric = \"angular\"  # 余弦相似度（Annoy 支持）\n    def load_index(self):\n        if self.index_path.exists():\n            self.index = AnnoyIndex(self.dim, self.distance_metric)\n            self.index.load(str(self.index_path))\n            if self.metadata_path.exists():\n                with open(self.metadata_path, 'r', encoding='utf-8') as f:\n                    self.metadata = json.load(f)\n            print(f\"Loaded Annoy index with {len(self.metadata)} chunks\")\n        else:\n            self.index = AnnoyIndex(self.dim, self.distance_metric)\n            print(\"No existing Annoy index found\")\n    def add_chunks(self, chunks, embeddings):\n        if not embeddings:\n            return\n        # 确保嵌入是 numpy 数组\n        embeddings = np.array(embeddings).astype('float32')\n        # 添加向量到 Annoy 索引\n        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n            chunk_id = chunk[\"chunk_id\"]\n            self.index.add_item(i, embedding.tolist())\n            self.metadata[chunk_id] = {\n                \"text\": chunk[\"text\"],\n                \"source\": chunk[\"source\"],\n                \"embedding\": embedding.tolist()\n            }\n        # 构建索引（n_trees 控制树的数量，影响精度和速度）\n        self.index.build(10)  # 默认 10 棵树\n        self.save_index()\n    def similarity_search(self, query_embedding, top_k=5):\n        query_embedding = np.array([query_embedding]).astype('float32')\n        # 获取最近邻（返回索引列表）\n        indices, distances = self.index.get_nns_by_vector(query_embedding[0], top_k, include_distances=True)\n        results = []\n        for idx, distance in zip(indices, distances):\n            if idx < len(self.metadata):\n                chunk_ids = list(self.metadata.keys())\n                chunk_id = chunk_ids[idx]\n                chunk_data = self.metadata[chunk_id]\n                # Annoy 的余弦相似度范围是 [0, 1]，0 表示完全不相似\n                score = 1 - distance  # 转换为相似度得分\n                results.append((score, chunk_id, chunk_data))\n        return sorted(results, key=lambda x: x[0], reverse=True)\n    def save_index(self):\n        self.index.save(str(self.index_path))\n        with open(self.metadata_path, 'w', encoding='utf-8') as f:\n            json.dump(self.metadata, f, ensure_ascii=False, indent=2)\n        print(f\"Saved Annoy index with {len(self.metadata)} chunks\")"
    },
    {
      "filename": "backend\\ai_service.py",
      "content": "import requests\nfrom typing import Dict, Any, Optional\nfrom RAG import initialize_rag_system\n\nclass AIService:\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.model_type = config.get('model_type', 'ollama')\n        self.model_name = config.get('model_name', 'qwen:7b')\n        self.rag_retriever = initialize_rag_system()\n        \n    def generate_response(self, prompt: str, use_rag: bool = False) -> str:\n        \"\"\"生成AI回复，支持RAG\"\"\"\n        rag_context = None\n        if use_rag:\n            rag_context = self.rag_retriever.retrieve(prompt)\n        \n        full_prompt = self._build_prompt(prompt, rag_context)\n        \n        if self.model_type == 'ollama':\n            return self._call_ollama(full_prompt)\n        elif self.model_type == 'openai':\n            return self._call_openai(full_prompt)\n        # 可扩展其他API\n        \n    def _build_prompt(self, prompt: str, context: Optional[str]) -> str:\n        \"\"\"构建最终提示词，整合RAG内容\"\"\"\n        if context:\n            return (\n                f\"<|im_start|>system\\n\"\n                f\"你是一个AI助手，请基于以下上下文信息回答问题：\\n\\n\"\n                f\"{context}\\n\"\n                f\"<|im_end|>\\n\"\n                f\"<|im_start|>user\\n\"\n                f\"{prompt}\\n\"\n                f\"<|im_end|>\\n\"\n                f\"<|im_start|>assistant\\n\"\n            )\n        return (\n            f\"<|im_start|>user\\n\"\n            f\"{prompt}\\n\"\n            f\"<|im_end|>\\n\"\n            f\"<|im_start|>assistant\\n\"\n        )\n    \n    def _call_ollama(self, prompt: str) -> str:\n        \"\"\"调用本地Ollama服务\"\"\"\n        try:\n            url = \"http://localhost:11434/api/generate\"\n            payload = {\n                \"model\": self.model_name,\n                \"prompt\": prompt,\n                \"stream\": False\n            }\n            response = requests.post(url, json=payload, timeout=300)\n            return response.json().get(\"response\", \"\")\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n    \n    def _call_openai(self, prompt: str) -> str:\n        \"\"\"调用OpenAI API（预留）\"\"\"\n        # 实际使用时替换为真实API调用\n        return f\"OpenAI response to: {prompt}\"\n    \n    # backend/ai_service.py\n    def update_config(self, new_config: Dict[str, Any]):\n        self.config.update(new_config)\n        self.model_type = self.config.get('model_type', self.model_type)\n        self.model_name = self.config.get('model_name', self.model_name)\n        # 重新初始化 Retriever\n        self.rag_retriever = initialize_rag_system()"
    },
    {
      "filename": "backend\\main.py",
      "content": "from fastapi import FastAPI, HTTPException, UploadFile, File\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.staticfiles import StaticFiles\nfrom pydantic import BaseModel\nfrom ai_service import AIService\nimport os\nfrom pathlib import Path\nfrom RAG.document_loader import DocumentLoader\nfrom fastapi.responses import FileResponse\nfrom RAG import initialize_rag_system\n\nBASE_DIR = Path(__file__).resolve().parent.parent\napp = FastAPI()\n# 添加静态文件服务\n    \napp.mount(\"/static\", StaticFiles(directory=BASE_DIR / \"frontend\"), name=\"static\")\n\n\n# 允许跨域\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# 初始化服务\nai_config = {\"model_type\": \"ollama\", \"model_name\": \"qwen:7b\"}\nai_service = AIService(ai_config)\n\nclass ChatRequest(BaseModel):\n    message: str\n    use_rag: bool = False\n\n@app.post(\"/chat\")\nasync def chat_endpoint(request: ChatRequest):\n    try:\n        response = ai_service.generate_response(request.message, request.use_rag)\n        return {\"response\": response}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/update_config\")\nasync def update_config(new_config: dict):\n    ai_service.update_config(new_config)\n    return {\"status\": \"config updated\"}\n\n# main.py中新增\n@app.post(\"/rebuild_index\")\nasync def rebuild_index():\n    ai_service.rag_retriever = initialize_rag_system(force_rebuild=True)\n    return {\"status\": \"index rebuilt\"}\n# 修改上传文档端点\n\n@app.post(\"/upload_document\")\nasync def upload_document(file: UploadFile = File(...)):\n    try:\n        documents_dir = BASE_DIR / \"data\" / \"documents\"\n        documents_dir.mkdir(parents=True, exist_ok=True)\n        file_path = documents_dir / file.filename\n        with open(file_path, \"wb\") as f:\n            content = await file.read()\n            f.write(content)\n        # 重新加载向量存储\n        ai_service.rag_retriever.vector_store.load_index()\n        return {\"status\": \"success\", \"file_path\": str(file_path)}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n# 添加前端服务\n@app.get(\"/\")\nasync def serve_frontend():\n    return FileResponse(BASE_DIR / \"frontend\" / \"index.html\")\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n     "
    },
    {
      "filename": "backend\\rag.py",
      "content": ""
    },
    {
      "filename": "backend\\requirements.txt",
      "content": "# requirements.txt\nfastapi>=0.68.0\nuvicorn>=0.18.3\nrequests>=2.31.0\nnumpy>=1.24.3\nPyPDF2>=3.0.1\npython-docx>=0.8.11\nmarkdown>=3.4.1\nlangchain-text-splitters>=0.0.1\nannoy>=1.17.0  # 可选gpu版本或cpu版本，pip安装无效就用conda"
    },
    {
      "filename": "config.py",
      "content": "import os\n\n# 基础路径配置\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nDATA_DIR = os.path.join(BASE_DIR, 'data')\nDOCUMENTS_DIR = os.path.join(DATA_DIR, 'documents')\nVECTOR_STORE_DIR = os.path.join(DATA_DIR, 'vector_store')\n\n# RAG配置\nRAG_CONFIG = {\n    # 文档加载配置\n    \"document_loader\": {\n        \"extensions\": [\".txt\", \".pdf\", \".docx\", \".pptx\", \".md\"]\n    },\n    \n    # 文本分割配置\n    \"text_splitter\": {\n        \"chunk_size\": 1000,\n        \"chunk_overlap\": 200\n    },\n    \n    # 嵌入模型配置\n    \"embeddings\": {\n        \"model_type\": \"ollama\",  # ollama 或 huggingface\n        \"model_name\": \"nomic-embed-text\"\n    },\n    \n    # 向量存储配置\n    \"vector_store\": {\n        \"type\": \"faiss\",  # faiss 或 chroma\n        \"index_name\": \"document_index\"\n    },\n    \n    # 检索器配置\n    \"retriever\": {\n        \"top_k\": 4,\n        \"score_threshold\": 0.6\n    }\n}"
    },
    {
      "filename": "frontend\\index.html",
      "content": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>AI Chat Module</title>\n    <link rel=\"stylesheet\" href=\"/static/style.css\">\n    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n    <script src=\"https://cdn.jsdelivr.net/npm/dompurify@3.0.5/dist/purify.min.js\"></script>\n</head>\n<body>\n    <div class=\"chat-container\">\n        <div id=\"chat-history\" class=\"chat-history\"></div>\n        \n        <div class=\"input-area\">\n            <input type=\"text\" id=\"user-input\" placeholder=\"Type your message...\">\n            <button onclick=\"sendMessage()\">Send</button>\n            <label>\n                <input type=\"checkbox\" id=\"use-rag\"> Use RAG\n            </label>\n        </div>\n        <!-- 在配置面板下方添加 -->\n<div class=\"document-upload\">\n    <h3>上传文档</h3>\n    <input type=\"file\" id=\"document-file\">\n    <button onclick=\"uploadDocument()\">上传</button>\n    <div id=\"upload-status\"></div>\n</div>\n        <div class=\"config-panel\">\n            <h3>Configuration</h3>\n            <select id=\"model-type\">\n                <option value=\"ollama\">Ollama (Local)</option>\n                <option value=\"openai\">OpenAI API</option>\n            </select>\n            <input type=\"text\" id=\"model-name\" placeholder=\"Model name\" value=\"llama3\">\n            <button onclick=\"updateConfig()\">Update Config</button>\n        </div>\n    </div>\n\n    <script src=\"/static/script.js\"></script>\n</body>\n</html>"
    },
    {
      "filename": "frontend\\script.js",
      "content": "let chatHistory = [];\n\nasync function sendMessage() {\n    const input = document.getElementById('user-input');\n    const message = input.value.trim();\n    const useRag = document.getElementById('use-rag').checked;\n    \n    if (!message) return;\n    \n    // 添加用户消息\n    addMessage('user', message);\n    input.value = '';\n    \n    try {\n        // 发送到后端\n        const response = await fetch('http://localhost:8000/chat', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json'\n            },\n            body: JSON.stringify({\n                message: message,\n                use_rag: useRag\n            })\n        });\n        \n        const data = await response.json();\n        addMessage('ai', data.response);\n    } catch (error) {\n        addMessage('ai', `Error: ${error.message}`);\n    }\n}\n\nasync function updateConfig() {\n    const modelType = document.getElementById('model-type').value;\n    const modelName = document.getElementById('model-name').value;\n    \n    try {\n        await fetch('http://localhost:8000/update_config', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json'\n            },\n            body: JSON.stringify({\n                model_type: modelType,\n                model_name: modelName\n            })\n        });\n        alert('Configuration updated successfully!');\n    } catch (error) {\n        alert(`Update failed: ${error.message}`);\n    }\n}\nasync function uploadDocument() {\n    const fileInput = document.getElementById('document-file');\n    const file = fileInput.files[0];\n    const statusDiv = document.getElementById('upload-status');\n    \n    if (!file) {\n        statusDiv.textContent = \"请选择文件\";\n        return;\n    }\n    \n    statusDiv.textContent = \"上传中...\";\n    \n    try {\n        const formData = new FormData();\n        formData.append('file', file);\n        \n        const response = await fetch('http://localhost:8000/upload_document', {\n            method: 'POST',\n            body: formData\n        });\n        \n        const data = await response.json();\n        if (data.status === 'success') {\n            statusDiv.textContent = `上传成功: ${data.file_path}`;\n            // 清空文件输入\n            fileInput.value = '';\n        } else {\n            statusDiv.textContent = `上传失败: ${data.detail || '未知错误'}`;\n        }\n    } catch (error) {\n        statusDiv.textContent = `上传错误: ${error.message}`;\n    }\n}\n\n// 添加页面加载事件\ndocument.addEventListener('DOMContentLoaded', () => {\n    // 初始加载完成后滚动到底部\n    const chatHistory = document.getElementById('chat-history');\n    chatHistory.scrollTop = chatHistory.scrollHeight;\n});\nfunction addMessage(role, content) {\n    const chatHistoryElement = document.getElementById('chat-history');\n    const messageDiv = document.createElement('div');\n    messageDiv.className = `message ${role}-message`;\n    \n    const contentDiv = document.createElement('div');\n    contentDiv.className = 'ai-message-content';\n    \n    // 安全渲染Markdown\n    if (role === 'ai') {\n        const sanitized = DOMPurify.sanitize(marked.parse(content));\n        contentDiv.innerHTML = sanitized;\n    } else {\n        contentDiv.textContent = content;\n    }\n    \n    messageDiv.appendChild(contentDiv);\n    chatHistoryElement.appendChild(messageDiv);\n    \n    // 滚动到底部\n    chatHistoryElement.scrollTop = chatHistoryElement.scrollHeight;\n    \n    // 保存历史\n    chatHistory.push({ role, content });\n}\n\n// 输入框回车发送\ndocument.getElementById('user-input').addEventListener('keypress', (e) => {\n    if (e.key === 'Enter') sendMessage();\n});"
    },
    {
      "filename": "frontend\\style.css",
      "content": "body {\n    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n    background-color: #f5f5f5;\n    display: flex;\n    justify-content: center;\n    padding: 20px;\n    line-height: 1.6;\n}\n\n.chat-container {\n    width: 100%;\n    max-width: 800px;\n    background: white;\n    border-radius: 10px;\n    box-shadow: 0 0 20px rgba(0,0,0,0.1);\n    overflow: hidden;\n    display: flex;\n    flex-direction: column;\n    height: 90vh;\n}\n.document-upload {\n    padding: 15px;\n    background: #f0f0f0;\n    border-top: 1px solid #ddd;\n    display: flex;\n    flex-direction: column;\n    gap: 10px;\n}\n\n.document-upload h3 {\n    margin: 0 0 10px 0;\n    font-size: 16px;\n    color: #444;\n}\n\n.document-upload input[type=\"file\"] {\n    padding: 8px;\n    background: white;\n    border: 1px solid #ccc;\n    border-radius: 4px;\n}\n.chat-history {\n    flex: 1;\n    padding: 20px;\n    overflow-y: auto;\n    display: flex;\n    flex-direction: column;\n    gap: 15px;\n}\n\n.message {\n    max-width: 80%;\n    padding: 15px;\n    border-radius: 12px;\n    line-height: 1.6;\n    box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n}\n\n.user-message {\n    align-self: flex-end;\n    background: linear-gradient(135deg, #4e8cff, #3a75e0);\n    color: white;\n    border-bottom-right-radius: 5px;\n}\n\n.ai-message {\n    align-self: flex-start;\n    background-color: #fafafa;\n    color: #333;\n    border-bottom-left-radius: 5px;\n}\n\n.ai-message-content {\n    overflow-wrap: break-word;\n}\n\n/* Markdown样式增强 */\n.markdown-content h1, .markdown-content h2, .markdown-content h3 {\n    margin-top: 1.2em;\n    margin-bottom: 0.6em;\n    padding-bottom: 0.2em;\n    border-bottom: 1px solid #eee;\n    color: #2c3e50;\n}\n\n.markdown-content h1 {\n    font-size: 1.8em;\n}\n\n.markdown-content h2 {\n    font-size: 1.5em;\n}\n\n.markdown-content h3 {\n    font-size: 1.3em;\n}\n\n.markdown-content p {\n    margin: 0.8em 0;\n}\n\n.markdown-content ul, .markdown-content ol {\n    margin: 0.8em 0;\n    padding-left: 1.5em;\n}\n\n.markdown-content li {\n    margin: 0.4em 0;\n}\n\n.markdown-content blockquote {\n    margin: 1em 0;\n    padding: 0.8em 1em;\n    background-color: #f8f9fa;\n    border-left: 4px solid #4e8cff;\n    color: #555;\n    border-radius: 0 8px 8px 0;\n}\n\n/* 代码块样式 - 淡蓝色背景 */\n.markdown-content pre {\n    background-color: #e6f7ff; /* 淡蓝色背景 */\n    padding: 15px;\n    border-radius: 8px;\n    overflow-x: auto;\n    margin: 1.2em 0;\n    box-shadow: inset 0 0 5px rgba(0,0,0,0.05);\n    border: 1px solid #c0e6ff;\n}\n\n.markdown-content code {\n    font-family: 'Fira Code', 'Consolas', monospace;\n    background-color: rgba(230, 247, 255, 0.3);\n    padding: 2px 6px;\n    border-radius: 4px;\n    color: #d63384;\n}\n\n.markdown-content pre code {\n    background: none;\n    padding: 0;\n    border-radius: 0;\n    color: #333;\n}\n\n/* 表格样式 */\n.markdown-content table {\n    width: 100%;\n    border-collapse: collapse;\n    margin: 1.2em 0;\n    background-color: #fff;\n    box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n}\n\n.markdown-content th, .markdown-content td {\n    padding: 10px 15px;\n    text-align: left;\n    border: 1px solid #e1e4e8;\n}\n\n.markdown-content th {\n    background-color: #f6f8fa;\n    font-weight: 600;\n}\n\n.markdown-content tr:nth-child(even) {\n    background-color: #fafbfc;\n}\n\n/* 流程图/图表容器样式 */\n.markdown-content .mermaid, \n.markdown-content .flowchart, \n.markdown-content .graphviz {\n    background-color: #a5c0cd; /* 淡蓝色背景 */\n    padding: 15px;\n    border-radius: 8px;\n    margin: 1.2em 0;\n    overflow-x: auto;\n    text-align: center;\n    border: 1px solid #c0e6ff;\n}\n\n/* 水平线样式 */\n.markdown-content hr {\n    border: 0;\n    height: 1px;\n    background: linear-gradient(to right, rgba(0,0,0,0), rgba(78,140,255,0.5), rgba(0,0,0,0));\n    margin: 1.5em 0;\n}\n\n/* 链接样式 */\n.markdown-content a {\n    color: #1e6bb8;\n    text-decoration: none;\n    border-bottom: 1px dashed #4e8cff;\n    transition: all 0.2s;\n}\n\n.markdown-content a:hover {\n    color: #0d4a9e;\n    border-bottom: 1px solid #0d4a9e;\n}\n\n/* 键盘标签样式 */\n.markdown-content kbd {\n    background-color: #f6f8fa;\n    border: 1px solid #d1d5da;\n    border-radius: 4px;\n    box-shadow: inset 0 -1px 0 #d1d5da;\n    color: #444d56;\n    display: inline-block;\n    font-family: monospace;\n    font-size: 0.9em;\n    line-height: 1;\n    padding: 3px 5px;\n    vertical-align: middle;\n}\n\n/* 提示框样式 */\n.markdown-content .tip, \n.markdown-content .note, \n.markdown-content .warning {\n    padding: 12px 15px;\n    margin: 1.2em 0;\n    border-radius: 8px;\n    border-left: 4px solid;\n}\n\n.markdown-content .tip {\n    background-color: #e6f7ff;\n    border-color: #4e8cff;\n}\n\n.markdown-content .note {\n    background-color: #fff8e6;\n    border-color: #ffc53d;\n}\n\n.markdown-content .warning {\n    background-color: #ffebee;\n    border-color: #f44336;\n}\n\n.input-area {\n    display: flex;\n    padding: 15px;\n    background: #f9f9f9;\n    border-top: 1px solid #eee;\n    gap: 10px;\n    align-items: center;\n}\n\n.input-area input {\n    flex: 1;\n    padding: 12px 18px;\n    border: 1px solid #ddd;\n    border-radius: 25px;\n    font-size: 16px;\n    outline: none;\n    transition: border-color 0.3s;\n}\n\n.input-area input:focus {\n    border-color: #4e8cff;\n    box-shadow: 0 0 0 2px rgba(78, 140, 255, 0.2);\n}\n\n.input-area button {\n    padding: 12px 24px;\n    background: linear-gradient(135deg, #4e8cff, #3a75e0);\n    color: white;\n    border: none;\n    border-radius: 25px;\n    cursor: pointer;\n    font-weight: bold;\n    transition: all 0.2s;\n    box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n}\n\n.input-area button:hover {\n    background: linear-gradient(135deg, #3a75e0, #2a65d0);\n    transform: translateY(-2px);\n    box-shadow: 0 4px 8px rgba(0,0,0,0.15);\n}\n\n.config-panel {\n    padding: 15px;\n    background: #f0f0f0;\n    border-top: 1px solid #ddd;\n    display: flex;\n    gap: 10px;\n    align-items: center;\n    flex-wrap: wrap;\n}\n\n.config-panel h3 {\n    margin: 0;\n    font-size: 16px;\n    color: #444;\n}\n\n.config-panel select, .config-panel input {\n    padding: 8px 12px;\n    border: 1px solid #ccc;\n    border-radius: 4px;\n    background: white;\n    font-size: 14px;\n}\n\n.config-panel button {\n    padding: 8px 15px;\n    background: #5a6268;\n    color: white;\n    border: none;\n    border-radius: 4px;\n    cursor: pointer;\n    transition: background 0.2s;\n}\n\n.config-panel button:hover {\n    background: #484e53;\n}\n\n/* 滚动条美化 */\n.chat-history::-webkit-scrollbar {\n    width: 8px;\n}\n\n.chat-history::-webkit-scrollbar-track {\n    background: #f1f1f1;\n    border-radius: 4px;\n}\n\n.chat-history::-webkit-scrollbar-thumb {\n    background: #c1c1c1;\n    border-radius: 4px;\n}\n\n.chat-history::-webkit-scrollbar-thumb:hover {\n    background: #a8a8a8;\n}"
    },
    {
      "filename": "run_demo.py",
      "content": "import subprocess\nimport webbrowser\nimport time\nimport os\nimport shutil\nimport sys\nfrom pathlib import Path\n\n\nif getattr(sys, 'frozen', False):\n    BASE_DIR = Path(sys.executable)\nelse:\n    BASE_DIR = Path(__file__).resolve().parent\n\n\ndef initialize_rag():\n    \"\"\"初始化RAG系统，强制重建向量索引\"\"\"\n    # 删除现有向量库\n    vector_store_dir = Path(\"data/vector_store\")\n    if vector_store_dir.exists():\n        shutil.rmtree(vector_store_dir)\n    \n    # 导入RAG初始化函数\n    from RAG import initialize_rag_system\n    \n    # 创建RAG系统\n    print(\"Initializing RAG system...\")\n    rag_retriever = initialize_rag_system(force_rebuild=True)\n    print(\"RAG system initialized successfully\")\n    return rag_retriever\n\ndef run_demo():\n    # 初始化RAG系统\n    initialize_rag()\n    backend_dir = os.path.join(os.path.dirname(__file__), 'backend')\n    # 启动后端\n    \n    backend_process = subprocess.Popen(\n        ['uvicorn', 'backend.main:app', '--reload'],  # 修改导入路径\n        cwd=os.path.dirname(__file__),  # 工作目录设为项目根目录\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE\n    )\n    \n    print(\"Starting backend server...\")\n    time.sleep(3)  # 等待服务器启动\n    \n    # 打开前端\n    print(\"Opening chat interface in browser...\")\n    webbrowser.open('http://localhost:8001')\n    \n    print(\"Chat interface opened. Press Ctrl+C to stop.\")\n    \n    try:\n        backend_process.wait()\n    except KeyboardInterrupt:\n        backend_process.terminate()\n        print(\"\\nServer stopped\")\n\nif __name__ == \"__main__\":\n    print(f\"!!! DEBUG: 静态文件路径 = {BASE_DIR / 'frontend'}\")\n    run_demo()"
    }
  ]
}